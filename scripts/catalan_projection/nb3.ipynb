{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metaphor Label Projection: Spanish to Catalan (Test Set)\n",
    "\n",
    "This notebook projects existing metaphor labels from a labeled Spanish test set to a parallel Catalan test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies...\n",
      "\n",
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Install required packages\n",
    "print(\"Installing dependencies...\")\n",
    "!pip install transformers torch awesome-align sentencepiece --quiet\n",
    "\n",
    "print(\"\\nSetup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Helper Functions\n",
    "\n",
    "These functions will read the data from the `.tsv` files and perform the label projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import awesome_align as align\n",
    "import os\n",
    "\n",
    "def read_conll_file(file_path):\n",
    "    \"\"\"Reads a CoNLL-style file and returns lists of sentences and labels.\"\"\"\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        current_sentence = []\n",
    "        current_labels = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if current_sentence:\n",
    "                    sentences.append(current_sentence)\n",
    "                    labels.append(current_labels)\n",
    "                    current_sentence = []\n",
    "                    current_labels = []\n",
    "            else:\n",
    "                parts = line.split('\\t')\n",
    "                token = parts[0]\n",
    "                label = parts[1] if len(parts) > 1 else 'O' # Default to 'O' if no label\n",
    "                current_sentence.append(token)\n",
    "                current_labels.append(label)\n",
    "        if current_sentence: # Add the last sentence if file doesn't end with a newline\n",
    "            sentences.append(current_sentence)\n",
    "            labels.append(current_labels)\n",
    "    return sentences, labels\n",
    "\n",
    "def write_conll_file(file_path, sentences, labels):\n",
    "    \"\"\"Writes sentences and labels to a CoNLL-style file.\"\"\"\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        for i in range(len(sentences)):\n",
    "            for j in range(len(sentences[i])):\n",
    "                f.write(f\"{sentences[i][j]}\\t{labels[i][j]}\\n\")\n",
    "            f.write('\\n')\n",
    "\n",
    "def project_labels_conll(source_sents, target_sents, source_labels, output_file):\n",
    "    \"\"\"\n",
    "    Projects BIO labels from a source language file to a target language file.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProjecting labels to '{output_file}'...\")\n",
    "    # Load alignment model\n",
    "    aligner = align.AwesomeAlign(model_name_or_path='bert-base-multilingual-cased')\n",
    "    \n",
    "    assert len(source_sents) == len(target_sents) == len(source_labels), \"File line count mismatch.\"\n",
    "\n",
    "    projected_target_labels = []\n",
    "    for i in tqdm(range(len(source_sents)), desc=\"Processing items\"):\n",
    "        src_tokens, tgt_tokens, src_labels = source_sents[i], target_sents[i], source_labels[i]\n",
    "        src_sent_str = ' '.join(src_tokens)\n",
    "        tgt_sent_str = ' '.join(tgt_tokens)\n",
    "\n",
    "        try:\n",
    "            alignment_str = aligner.align(src_sent_str, tgt_sent_str)\n",
    "            alignments = [tuple(map(int, x.split('-'))) for x in alignment_str.split()]\n",
    "        except Exception as e:\n",
    "            print(f\"Could not align sentence pair {i}, skipping. Error: {e}\")\n",
    "            # Add 'O' labels for the unaligned sentence to keep counts consistent\n",
    "            projected_target_labels.append(['O'] * len(tgt_tokens))\n",
    "            continue\n",
    "\n",
    "        tgt_labels = ['O'] * len(tgt_tokens)\n",
    "        src_to_tgt_map = {s_idx: [] for s_idx in range(len(src_tokens))}\n",
    "        for s_idx, t_idx in alignments:\n",
    "            src_to_tgt_map[s_idx].append(t_idx)\n",
    "\n",
    "        for src_idx, label in enumerate(src_labels):\n",
    "            if label != 'O' and src_idx in src_to_tgt_map:\n",
    "                for tgt_idx in src_to_tgt_map[src_idx]:\n",
    "                    if tgt_idx < len(tgt_labels):\n",
    "                        # A more advanced implementation could handle B-I transitions\n",
    "                        tgt_labels[tgt_idx] = label\n",
    "        \n",
    "        projected_target_labels.append(tgt_labels)\n",
    "    \n",
    "    # Write the final output\n",
    "    write_conll_file(output_file, target_sents, projected_target_labels)\n",
    "    print(f\"Projection finished. Output at '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the Projection\n",
    "\n",
    "This block sets the file paths and executes the projection for the premise and hypothesis files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Catalan Label Projection for Test Set ---\n",
      "Reading source and target files...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hle_files/data/meta4xnli/detection/source_datasets/es/xnli_test_prem.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1661896908.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# --- Read Data ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading source and target files...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0msrc_prem_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_prem_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_conll_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSOURCE_PREMISE_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mtgt_prem_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_conll_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCATALAN_PREMISE_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-2519328407.py\u001b[0m in \u001b[0;36mread_conll_file\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mcurrent_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcurrent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hle_files/data/meta4xnli/detection/source_datasets/es/xnli_test_prem.tsv'"
     ]
    }
   ],
   "source": [
    "print(\"--- Starting Catalan Label Projection for Test Set ---\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# Source language data (Spanish - Labeled)\n",
    "SOURCE_PREMISE_FILE = \"hle_files/data/meta4xnli/detection/source_datasets/es/xnli_test_prem.tsv\"\n",
    "SOURCE_HYPOTHESIS_FILE = \"hle_files/data/meta4xnli/detection/source_datasets/es/xnli_test_hyp.tsv\"\n",
    "\n",
    "# Target language data (Catalan - Unlabeled)\n",
    "CATALAN_PREMISE_FILE = \"hle_files/data/meta4xnli/detection/source_datasets/ca/xnli_test_prem.tsv\"\n",
    "CATALAN_HYPOTHESIS_FILE = \"hle_files/data/meta4xnli/detection/source_datasets/ca/xnli_test_hyp.tsv\"\n",
    "\n",
    "# Final output paths\n",
    "output_dir = \"hle_files/data/output/projected_ca_test/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "PROJECTED_PREMISE_FILE = os.path.join(output_dir, \"meta4xnli_ca_test_prem.tsv\")\n",
    "PROJECTED_HYPOTHESIS_FILE = os.path.join(output_dir, \"meta4xnli_ca_test_hyp.tsv\")\n",
    "\n",
    "# --- Read Data ---\n",
    "print(\"Reading source and target files...\")\n",
    "src_prem_sents, src_prem_labels = read_conll_file(SOURCE_PREMISE_FILE)\n",
    "tgt_prem_sents, _ = read_conll_file(CATALAN_PREMISE_FILE)\n",
    "\n",
    "src_hyp_sents, src_hyp_labels = read_conll_file(SOURCE_HYPOTHESIS_FILE)\n",
    "tgt_hyp_sents, _ = read_conll_file(CATALAN_HYPOTHESIS_FILE)\n",
    "print('hi')\n",
    "# --- Project Labels ---\n",
    "project_labels_conll(src_prem_sents, tgt_prem_sents, src_prem_labels, PROJECTED_PREMISE_FILE)\n",
    "project_labels_conll(src_hyp_sents, tgt_hyp_sents, src_hyp_labels, PROJECTED_HYPOTHESIS_FILE)\n",
    "\n",
    "print(\"\\n--- Pipeline Finished Successfully! ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: awesome-align\n",
      "Version: 0.1.7\n",
      "Summary: An awesome word alignment tool\n",
      "Home-page: https://github.com/neulab/awesome-align\n",
      "Author: NeuLab\n",
      "Author-email: zdou0830@gmail.com\n",
      "License: BSD 3-Clause\n",
      "Location: c:\\users\\xavid\\anaconda3\\lib\\site-packages\n",
      "Requires: boto3, filelock, numpy, requests, tokenizers, torch, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show awesome-align\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
