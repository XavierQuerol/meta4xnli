{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metaphor Label Projection: ES/EN â†’ CA\n",
    "\n",
    "Based on **Meta4XNLI** methodology (Sanchez-Bayona & Agerri, 2025)\n",
    "\n",
    "This notebook projects metaphor labels from Spanish and English to Catalan using:\n",
    "- Word alignment (multilingual BERT embeddings)\n",
    "- BIO tag consistency enforcement\n",
    "- The projection methodology described in Section 3.2.1 of the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "!pip install transformers torch sentencepiece -q\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(\"âœ“ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive (if using Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    BASE_PATH = '/content/drive/MyDrive/HLE-project/data/meta4xnli/detection'  # Adjust to your data location\n",
    "except:\n",
    "    BASE_PATH = './'  # Local directory\n",
    "    print(\"Running locally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust these paths to match your file structure\n",
    "SOURCE_DIR = os.path.join(BASE_PATH, \"source_datasets_filtered\")\n",
    "OUTPUT_DIR = os.path.join(BASE_PATH, \"projected_labels\")\n",
    "\n",
    "# Files to process\n",
    "FILES = [\n",
    "    'xnli_dev_hyp.tsv',\n",
    "    'xnli_dev_prem.tsv',\n",
    "    'xnli_test_hyp.tsv',\n",
    "    'xnli_test_prem.tsv'\n",
    "]\n",
    "\n",
    "print(f\"Source directory: {SOURCE_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Files to process: {FILES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Alignment Model\n",
    "\n",
    "We use multilingual BERT for computing word alignments, following the paper's approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading multilingual BERT model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = AutoModel.from_pretrained('bert-base-multilingual-cased')\n",
    "model.eval()\n",
    "print(\"âœ“ Model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsv_file(filepath: str) -> List[Tuple[List[str], List[str]]]:\n",
    "    \"\"\"Read CoNLL-format TSV file.\"\"\"\n",
    "    sentences = []\n",
    "    current_tokens, current_labels = [], []\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if current_tokens:\n",
    "                    sentences.append((current_tokens, current_labels))\n",
    "                    current_tokens, current_labels = [], []\n",
    "            else:\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) >= 2:\n",
    "                    current_tokens.append(parts[0])\n",
    "                    current_labels.append(parts[1])\n",
    "    \n",
    "    if current_tokens:\n",
    "        sentences.append((current_tokens, current_labels))\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def write_tsv_file(filepath: str, sentences: List[Tuple[List[str], List[str]]]):\n",
    "    \"\"\"Write CoNLL-format TSV file.\"\"\"\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        for tokens, labels in sentences:\n",
    "            for token, label in zip(tokens, labels):\n",
    "                f.write(f\"{token}\\t{label}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "def align_tokens(src_tokens: List[str], tgt_tokens: List[str], \n",
    "                tokenizer, model, threshold: float = 0.7) -> Dict[int, List[int]]:\n",
    "    \"\"\"Align tokens using multilingual BERT embeddings.\"\"\"\n",
    "    src_text = \" \".join(src_tokens)\n",
    "    tgt_text = \" \".join(tgt_tokens)\n",
    "    \n",
    "    # Tokenize\n",
    "    src_encoded = tokenizer(src_text, return_tensors='pt', add_special_tokens=True)\n",
    "    tgt_encoded = tokenizer(tgt_text, return_tensors='pt', add_special_tokens=True)\n",
    "    \n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        src_embeddings = model(**src_encoded).last_hidden_state[0]\n",
    "        tgt_embeddings = model(**tgt_encoded).last_hidden_state[0]\n",
    "    \n",
    "    # Compute similarity\n",
    "    similarity = torch.matmul(src_embeddings, tgt_embeddings.T)\n",
    "    \n",
    "    # Map subwords to words\n",
    "    src_word_ids = src_encoded.word_ids()\n",
    "    tgt_word_ids = tgt_encoded.word_ids()\n",
    "    \n",
    "    # Build alignments\n",
    "    alignments = defaultdict(list)\n",
    "    \n",
    "    for src_idx in range(len(src_tokens)):\n",
    "        src_sub = [i for i, wid in enumerate(src_word_ids) if wid == src_idx]\n",
    "        if not src_sub:\n",
    "            continue\n",
    "            \n",
    "        for tgt_idx in range(len(tgt_tokens)):\n",
    "            tgt_sub = [i for i, wid in enumerate(tgt_word_ids) if wid == tgt_idx]\n",
    "            if not tgt_sub:\n",
    "                continue\n",
    "            \n",
    "            max_sim = max(similarity[s, t].item() for s in src_sub for t in tgt_sub)\n",
    "            \n",
    "            if max_sim > threshold:\n",
    "                if tgt_idx not in alignments[src_idx]:\n",
    "                    alignments[src_idx].append(tgt_idx)\n",
    "    \n",
    "    return dict(alignments)\n",
    "\n",
    "def fix_bio_consistency(labels: List[str]) -> List[str]:\n",
    "    \"\"\"Fix BIO tag consistency.\"\"\"\n",
    "    fixed = []\n",
    "    prev = 'O'\n",
    "    \n",
    "    for label in labels:\n",
    "        if label == 'I-METAPHOR' and prev not in ['B-METAPHOR', 'I-METAPHOR']:\n",
    "            fixed.append('B-METAPHOR')\n",
    "        else:\n",
    "            fixed.append(label)\n",
    "        prev = fixed[-1]\n",
    "    \n",
    "    return fixed\n",
    "\n",
    "def project_labels(src_tokens: List[str], src_labels: List[str],\n",
    "                  tgt_tokens: List[str], tokenizer, model) -> List[str]:\n",
    "    \"\"\"Project labels from source to target.\"\"\"\n",
    "    tgt_labels = ['O'] * len(tgt_tokens)\n",
    "    \n",
    "    # Get alignments\n",
    "    alignments = align_tokens(src_tokens, tgt_tokens, tokenizer, model)\n",
    "    \n",
    "    # Project metaphor labels\n",
    "    for src_idx, src_label in enumerate(src_labels):\n",
    "        if src_label != 'O' and src_idx in alignments:\n",
    "            for tgt_idx in alignments[src_idx]:\n",
    "                if tgt_idx < len(tgt_labels):\n",
    "                    tgt_labels[tgt_idx] = src_label\n",
    "    \n",
    "    # Fix BIO consistency\n",
    "    tgt_labels = fix_bio_consistency(tgt_labels)\n",
    "    \n",
    "    return tgt_labels\n",
    "\n",
    "print(\"âœ“ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Projection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_file(src_file: str, tgt_file: str, output_file: str, \n",
    "                tokenizer, model, lang_pair: str):\n",
    "    \"\"\"Project labels from source to target file.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Projecting: {os.path.basename(src_file)}\")\n",
    "    print(f\"Language pair: {lang_pair}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Read files\n",
    "    src_sentences = read_tsv_file(src_file)\n",
    "    tgt_sentences = read_tsv_file(tgt_file)\n",
    "    \n",
    "    if len(src_sentences) != len(tgt_sentences):\n",
    "        print(f\"âš  WARNING: Sentence count mismatch!\")\n",
    "        print(f\"  Source: {len(src_sentences)}, Target: {len(tgt_sentences)}\")\n",
    "    \n",
    "    # Project\n",
    "    projected = []\n",
    "    metaphor_count = 0\n",
    "    \n",
    "    for (src_tok, src_lab), (tgt_tok, _) in tqdm(zip(src_sentences, tgt_sentences), \n",
    "                                                   total=len(src_sentences),\n",
    "                                                   desc=\"Projecting\"):\n",
    "        proj_lab = project_labels(src_tok, src_lab, tgt_tok, tokenizer, model)\n",
    "        projected.append((tgt_tok, proj_lab))\n",
    "        metaphor_count += sum(1 for l in proj_lab if l != 'O')\n",
    "    \n",
    "    # Write output\n",
    "    write_tsv_file(output_file, projected)\n",
    "    \n",
    "    print(f\"\\nâœ“ Complete!\")\n",
    "    print(f\"  Projected {metaphor_count} metaphor tokens\")\n",
    "    print(f\"  Output: {output_file}\")\n",
    "    \n",
    "    return metaphor_count\n",
    "\n",
    "print(\"âœ“ Projection function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Projection: Spanish â†’ Catalan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SPANISH â†’ CATALAN PROJECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "es_ca_stats = {}\n",
    "\n",
    "for filename in FILES:\n",
    "    src_file = os.path.join(SOURCE_DIR, 'es', filename)\n",
    "    tgt_file = os.path.join(SOURCE_DIR, 'ca', filename)\n",
    "    output_file = os.path.join(OUTPUT_DIR, 'ca-es', filename)\n",
    "    \n",
    "    if os.path.exists(src_file) and os.path.exists(tgt_file):\n",
    "        count = project_file(src_file, tgt_file, output_file, \n",
    "                           tokenizer, model, \"ES â†’ CA\")\n",
    "        es_ca_stats[filename] = count\n",
    "    else:\n",
    "        print(f\"\\nâš  Skipping {filename} - files not found\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ES â†’ CA SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "for fname, count in es_ca_stats.items():\n",
    "    print(f\"  {fname}: {count} metaphor tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Projection: English â†’ Catalan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENGLISH â†’ CATALAN PROJECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "en_ca_stats = {}\n",
    "\n",
    "for filename in FILES:\n",
    "    src_file = os.path.join(SOURCE_DIR, 'en', filename)\n",
    "    tgt_file = os.path.join(SOURCE_DIR, 'ca', filename)\n",
    "    output_file = os.path.join(OUTPUT_DIR, 'ca-en', filename)\n",
    "    \n",
    "    if os.path.exists(src_file) and os.path.exists(tgt_file):\n",
    "        count = project_file(src_file, tgt_file, output_file, \n",
    "                           tokenizer, model, \"EN â†’ CA\")\n",
    "        en_ca_stats[filename] = count\n",
    "    else:\n",
    "        print(f\"\\nâš  Skipping {filename} - files not found\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"EN â†’ CA SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "for fname, count in en_ca_stats.items():\n",
    "    print(f\"  {fname}: {count} metaphor tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROJECTION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nOutput directories created:\")\n",
    "print(f\"  â€¢ {os.path.join(OUTPUT_DIR, 'ca-es')} (Spanish â†’ Catalan)\")\n",
    "print(f\"  â€¢ {os.path.join(OUTPUT_DIR, 'ca-en')} (English â†’ Catalan)\")\n",
    "\n",
    "print(\"\\nðŸ“Š Statistics:\")\n",
    "print(f\"\\nSpanish â†’ Catalan:\")\n",
    "for fname, count in es_ca_stats.items():\n",
    "    print(f\"  {fname}: {count} tokens\")\n",
    "    \n",
    "print(f\"\\nEnglish â†’ Catalan:\")\n",
    "for fname, count in en_ca_stats.items():\n",
    "    print(f\"  {fname}: {count} tokens\")\n",
    "\n",
    "print(\"\\nâš ï¸  Next Steps (from Meta4XNLI paper):\")\n",
    "print(\"  1. Manual review of projected labels\")\n",
    "print(\"  2. Correction of alignment errors\")\n",
    "print(\"  3. Addition of missed metaphors\")\n",
    "print(\"  4. Verification of BIO tag consistency\")\n",
    "print(\"  5. Inter-annotator agreement check (recommended)\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Key Findings from the Paper:\")\n",
    "print(\"  â€¢ Not all metaphors transfer across languages\")\n",
    "print(\"  â€¢ Translation affects metaphor preservation (see Table 9)\")\n",
    "print(\"  â€¢ Manual revision improved quality significantly\")\n",
    "print(\"  â€¢ Semi-automatic approach is efficient but needs validation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
